% Created 2017-04-23 Sun 16:29
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Jing-jiang Li}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={Jing-jiang Li},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.2.1 (Org mode 9.0.5)}, 
 pdflang={English}}
\begin{document}

\tableofcontents

\section{Youtube-8M Starter Code}
\label{sec:org7447352}

\subsection{Project Structure (Core Part)}
\label{sec:org95d6e78}

\subsubsection{Train (Model):}
\label{sec:org18064e6}

\begin{enumerate}
\item Related Files
\label{sec:org56e608b}

\begin{enumerate}
\item Processing Utility
\label{sec:orgf7330cb}
\begin{itemize}
\item train.py: The primary script for training models.
\item losses.py: Contains definitions for loss functions.
\item export\_model.py: Provides a class to export a model during training for later use in batch prediction.
\item readers.py: Contains definitions for the Video dataset and Frame dataset readers.
\end{itemize}
\item Models
\label{sec:org093eab1}
\begin{enumerate}
\item Model Utility
\label{sec:orgb53df69}
\begin{itemize}
\item models.py: Base class for defining a model. (common interface) - model\_util.py: Must implement to define a model
\end{itemize}
\item Model Processing Logic
\label{sec:org5d3e38f}
\begin{itemize}
\item video\_level\_models.py: take whole video (agreegated features) as input
\item frame\_level\_models.py: take frame level features as input
\end{itemize}
\end{enumerate}
\end{enumerate}
\item Model Analysis
\label{sec:org47974d4}

take video\_level\_models as an example:

it contains two sub models inside of it

\begin{itemize}
\item \texttt{LogisticModel}
\end{itemize}

\begin{verbatim}
class LogisticModel(models.BaseModel):

  def create_model(self, model_input, vocab_size, l2_penalty=1e-8,
**unused_params):
    output = slim.fully_connected(
        model_input, vocab_size, activation_fn=tf.nn.sigmoid,
        weights_regularizer=slim.l2_regularizer(l2_penalty))
    return {"predictions": output}
\end{verbatim}

\textbf{Analysis for this model}

\begin{itemize}
\item Input: matrix of input features/ number of classes in the dataset
\begin{itemize}
\item How to set up the input:

By chaning the --train\_data\_pattern flag, we can specify smaller data set.

To be more specific, using the following command

\begin{verbatim}
python train.py
--train_data_pattern='/path/to/features/train*.tfrecord'
--model=LogisticModel --train_dir=$MODEL_DIR/video_level_logistic_model
\end{verbatim}
\end{itemize}
\end{itemize}


\begin{itemize}
\item Output:A dictionary with a tensor containing the probability predictions of the model in the 'predictions' key.
\begin{itemize}
\item How to save the output:

By chaning the --train\_dir, we can specify where to store the result
\begin{verbatim}
python train.py
--train_data_pattern='/path/to/features/train*.tfrecord'
--model=LogisticModel --train_dir=$MODEL_DIR/video_level_logistic_model
\end{verbatim}
\end{itemize}

\item Processing Model: slim.fully\_connected from tensorflow. A specific layer from neural network.
Other layers
\begin{center}
\begin{tabular}{ll}
\hline
Layer & TF-Slim\\
\hline
BiasAdd & slim.bias\_add\\
BatchNorm & slim.batch\_norm\\
Conv2d & slim.conv2d\\
Conv2dInPlane & slim.conv2d\_in\_plane\\
Conv2dTranspose (Deconv) & slim.conv2d\_transpose\\
AvgPool2D & slim.avg\_pool2d\\
Dropout & slim.dropout\\
\hline
\end{tabular}
\end{center}
\end{itemize}




\begin{itemize}
\item \texttt{MoeModel}
\end{itemize}
\begin{verbatim}
class MoeModel(models.BaseModel):

  def create_model(self,
                   model_input,
                   vocab_size,
                   num_mixtures=None,
                   l2_penalty=1e-8,
                   **unused_params):
    num_mixtures = num_mixtures or FLAGS.moe_num_mixtures

    gate_activations = slim.fully_connected(
        model_input,
        vocab_size * (num_mixtures + 1),
        activation_fn=None,
        biases_initializer=None,
        weights_regularizer=slim.l2_regularizer(l2_penalty),
        scope="gates")
    expert_activations = slim.fully_connected(
        model_input,
        vocab_size * num_mixtures,
        activation_fn=None,
        weights_regularizer=slim.l2_regularizer(l2_penalty),
        scope="experts")

    gating_distribution = tf.nn.softmax(tf.reshape(
        gate_activations,
        [-1, num_mixtures + 1]))
    expert_distribution = tf.nn.sigmoid(tf.reshape(
        expert_activations,
        [-1, num_mixtures]))

    final_probabilities_by_class_and_batch = tf.reduce_sum(
        gating_distribution[:, :num_mixtures] * expert_distribution, 1)
    final_probabilities = tf.reshape(final_probabilities_by_class_and_batch,
                                     [-1, vocab_size])
    return {"predictions": final_probabilities}
\end{verbatim}

\textbf{How to build our own model}

\begin{enumerate}
\item The model should inherit \texttt{models.BaseModel}
\item Specify Input from command
\item Output should satisfy the format: \texttt{return \{"predictions": final\_probabilities\}}
\end{enumerate}
\end{enumerate}



\subsubsection{Evaluation}
\label{sec:org283b896}
We can use this part directly
\begin{enumerate}
\item Related Files
\label{sec:org3ce9f6f}
\begin{itemize}
\item eval.py: The primary script for evaluating models.
\item eval\_util.py: Provides a class that calculates all evaluation metrics.
\item average\_precision\_calculator.py: Functions for calculating average precision.
\item mean\_average\_precision\_calculator.py: Functions for calculating mean average precision.
\end{itemize}

\item How to use them
\label{sec:org1f04199}

Through command line:

To evaluate the model, run

\begin{verbatim}
python eval.py --eval_data_pattern='/path/to/features/validate*.tfrecord'
--model=LogisticModel
--train_dir=$MODEL_DIR/video_level_logistic_model --run_once=True
\end{verbatim}

As the model is training or evaluating, you can view the results on tensorboard by running

\begin{verbatim}
tensorboard --logdir=$MODEL_DIR
\end{verbatim}

and navigating to \url{http://localhost:6006} in your web browser.

When you are happy with your model, you can generate a csv file of predictions from it by running
\begin{verbatim}
python inference.py
--output_file=$MODEL_DIR/video_level_logistic_model/predictions.csv
--input_data_pattern='/path/to/features/test*.tfrecord'
--train_dir=$MODEL_DIR/video_level_logistic_model
\end{verbatim}
This will output the top 20 predicted labels from the model for every example to 'predictions.csv'.
\end{enumerate}

\subsubsection{Others}
\label{sec:org3ae6745}

No need to touch other files

\subsection{Set up Pycharm Development Environment}
\label{sec:orgb917edf}
\section{How to insert our own model}
\label{sec:org8aba012}
\subsection{Where to put the model}
\label{sec:orgc99ad49}

In file: \texttt{video\_level\_models.py}, insert the following code

\begin{verbatim}
class RegressorModel(models.BaseModel):
  """Logistic model with L2 regularization."""

  def create_model(self, model_input, vocab_size, l2_penalty=1e-8, **unused_params):
    """Creates a logistic model.

    Args:
      model_input: 'batch' x 'num_features' matrix of input features.
      vocab_size: The number of classes in the dataset.

    Returns:
      A dictionary with a tensor containing the probability predictions of the
      model in the 'predictions' key. The dimensions of the tensor are
      batch_size x num_classes."""

    vid_ids = []
    labels = []
    labels_for_MLP = []
    mean_rgb = []
    mean_audio = []

    i=0
    label_mapping = pd.Series.from_csv('label_names.csv',header=0).to_dict()
    n = len(label_mapping)

    print ("=====================")
    print (model_input)
    print ("=====================")
    for example in tf.python_io.tf_record_iterator("train-0.tfrecord"):
        tf_example = tf.train.Example.FromString(example) # get visualized TFRecord
        vid_ids.append(tf_example.features.feature['video_id']
                       .bytes_list.value[0].decode(encoding='UTF-8'))

        array = np.zeros(n)
        tmp_labels=tf_example.features.feature['labels'].int64_list.value
        tmp_labels_after_pp = []
        for x in tmp_labels:
            if x<4716:
                tmp_labels_after_pp.append(x)
        labels.append(tmp_labels_after_pp)
        array[tmp_labels]=1
        labels_for_MLP.append(array)

        mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)
        mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)

    output = slim.fully_connected(
        model_input, vocab_size, activation_fn=tf.nn.sigmoid,
        weights_regularizer=slim.l2_regularizer(l2_penalty))

    X = mean_audio #[[0., 0.], [1., 1.]]
    y = labels_for_MLP #[[0, 1, 1], [1, 1, 0], [1, 0, 0]]
    clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,),
                       random_state=1)
    clf.fit(X, y)
    # clf.predict([[2., 2.], [-1., -2.]])
    result1 = clf.predict([mean_audio[8]])
    result_tensor = tf.convert_to_tensor(result1)
    return {"predictions": result_tensor}
\end{verbatim}


\subsection{Convert between tensor with np array}
\label{sec:orgbba1067}

\subsubsection{np array to tensor}
\label{sec:orga2c3009}

\begin{verbatim}
result1 = clf.predict([mean_audio[8]])
result_tensor = tf.convert_to_tensor(result1)
\end{verbatim}

\subsubsection{tensor to np array}
\label{sec:org41426d6}
\begin{verbatim}
# create a new session firstly as default session
sess = tf.InteractiveSession()
# after calling eval() function, we can print out the result
print(output.eval())
\end{verbatim}
\end{document}
